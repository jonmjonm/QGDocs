[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site gives introductions to some of the tools developed by the Duke Quantifying Gerrymandering group. The group, headed by Jonathan C. Mattingly and Gregory J. Herschlag, works to understand how to assess the degree to which political districts capture the will of the people in the elections in which they are used. More information see the groups blog."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantifying Gerrymandering Documentation",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "cycleWalk.html",
    "href": "cycleWalk.html",
    "title": "Cycle Walk",
    "section": "",
    "text": "CycleWalk.jl is a registered Julia package that implements the Metropolized Cycle Walk algorithm which is used to sample a used specified distribution on the space of political redistricting plans. This MCMC algorithm is used to create ensemble of redistricting plans that can be used to analyze the impact of different redistricting plans on electoral outcomes.\nMetropolized Cycle Walk supports number of different score/energy functions which are used to define the distribution. The distribution encodes the legal and policy preferences.\nMetropolized Cycle Walk outputs the sampled redistricting into an Atlas file. AtlasIO files can be loaded using Julia or Python using the AtlasIO.jl library.",
    "crumbs": [
      "Home",
      "Cycle Walk"
    ]
  },
  {
    "objectID": "cycleWalk.html#overview",
    "href": "cycleWalk.html#overview",
    "title": "Cycle Walk",
    "section": "",
    "text": "CycleWalk.jl is a registered Julia package that implements the Metropolized Cycle Walk algorithm which is used to sample a used specified distribution on the space of political redistricting plans. This MCMC algorithm is used to create ensemble of redistricting plans that can be used to analyze the impact of different redistricting plans on electoral outcomes.\nMetropolized Cycle Walk supports number of different score/energy functions which are used to define the distribution. The distribution encodes the legal and policy preferences.\nMetropolized Cycle Walk outputs the sampled redistricting into an Atlas file. AtlasIO files can be loaded using Julia or Python using the AtlasIO.jl library.",
    "crumbs": [
      "Home",
      "Cycle Walk"
    ]
  },
  {
    "objectID": "cycleWalk.html#the-metropolized-cycle-walk-algorithm",
    "href": "cycleWalk.html#the-metropolized-cycle-walk-algorithm",
    "title": "Cycle Walk",
    "section": "The Metropolized Cycle Walk Algorithm",
    "text": "The Metropolized Cycle Walk Algorithm\nThe basic Cycle Walk produced \\(d\\)-tree spanning forests where each of the \\(d\\)-spanning trees is approximately balanced in the sense that the total population of each tree is approximately balanced.\nOne step of the Cycle Walk proceeds by either proposing a 1-Tree Cycle Walk or a 2-Tree Cycle Walk. The 1-Tree Cycle Walk adds an edge the tree and then removes and edge from cycle this addition creates so that one again has a tree. The 2-Tree Cycle Walk adds two edges between two adjacent trees and then removes two edges from the cycle these additions creates so that one again has two trees.\nThe Metropolized Cycle Walk algorithm uses these walks as proposals to a Metropolis-Hastings algorithm to sample from a specified target distribution.\nMore details on the algorithm can be found in the [Cycle Walk paper].",
    "crumbs": [
      "Home",
      "Cycle Walk"
    ]
  },
  {
    "objectID": "cycleWalk.html#instillation",
    "href": "cycleWalk.html#instillation",
    "title": "Cycle Walk",
    "section": "Instillation",
    "text": "Instillation\nThe latest released version of the `CycleWalk.jl’ package can be installed from with in Julia by\nusing Pkg\nPkg.add(\"CycleWalk\")\nThis can be done from the commandline in a terminal with\njulia -e 'using Pkg; Pkg.add(\"CycleWalk\")'\n\nLocal Environments\nIt is recommended that you run your Julia session in a local environment to minimize unanticipated side effects from other (unneeded) packages. To add the CycleWalk package to a local environment in the current working directory\nusing Pkg\nPkg.activate(\".\")       # replace this path to keep the local \n                        # environment somewhere else or with a specified name \nPkg.add(\"CycleWalk\")",
    "crumbs": [
      "Home",
      "Cycle Walk"
    ]
  },
  {
    "objectID": "cycleWalk.html#examples",
    "href": "cycleWalk.html#examples",
    "title": "Cycle Walk",
    "section": "Examples",
    "text": "Examples\nIn each example, we will step through the commands task by task. At the end of the section we will collect all of the commands into a complete script you can copy and execute.\n\nA first example: 4x4 rectangular grid\nOur first example will be on a small 4x4 rectangular graph. We choose this example because it executes fast and produces relatively small files. that can be examined by hand. The first step is to download the needed JSON adjacency file. For this example it is call grid_graph_4_by_4.json and was discussed more fully in this Section on JSON Adjacency Files. You can download the file to current directory using the following commandline at the terminal\ncurl   https://jonmjonm.github.io/QGDocs/Geo/Adjacency/grid_graph_4_by_4.json -o grid_graph_4_by_4.json\nNow that we have the needed JSON adjacency file, open a Julia session in the directory with that datafile. We begin by activating out local environment where we have installed the CycleWalk Package and loading the CycleWalk and RandomNumbers packages. If you have not installed the RandomNumbers package you need to execute Pkg.add(\"RandomNumbers\") in a julia window. Make sure you have already activated the environment you intend to use.\nusing Pkg\nPkg.activate(\".\")       #   activate environment \nusing RandomNumbers     #   load Random Number package\nusing CycleWalk         #   load Cycle Walk package\n\nBuild the Graph\nTo load the graph we begin by setting the path to the adjacency file; called grid_graph_4_by_4.json in this case. Next we create a set holding all of the variable names we want to load from the adjacency file. Lastly, we build the graph by specifying the file name, the variable that holds th population and the nodes names, and all of the node data you want load. You need to specify which of the node data names hold the area, border length, and edge parameter data.\n## build graph\npctGraphPath = joinpath(\".\",\"grid_graph_4_by_4.json\")\nnodeData = Set([\"node_name\", \"county\", \"population\", \"area\", \"border_length\"]);\ngraph = build_graph(pctGraphPath, \"population\", \"node_name\", nodeData;\n              area_col=\"area\", node_border_col=\"border_length\", \n              edge_perimeter_col=\"length\")\nThe variable graph is a structure that contains all of the adjacency data as well as all of the data on the vertices and edges.\n\n\nInitialize a random Forest Partitions with specified Constraints\nWe now define the constraints on the phasespace. We specify the number of connected districts in our forest partition. We will use the term Forest Partition with \\(d\\) elements to describe a spanning forest with \\(d\\) disjoint spanning trees. The vertices/nodes in each spanning tree will be the elements of the partition of vertices/nodes induced by the Forest Partition. Beyond the number of constraints, in this case we will also add an absolute constraint on the population deviation. We will require all partitions (also referred to as distractings) to have elements whose relative population deviation from the ideal population is less than allowed_pop_dev. The ideal population is calculated by \\[\\text{Ideal Population}=\\frac{\\text{Total Population}}{\\text{Number of Districts}}\\] then the relative population deviation of the \\(i\\)th district is given by \\[ \\text{$i$th relative population deviation}= \\frac{\\big|\\text{$i$th District Population} - \\text{Ideal Population}\\big|}{\\text{Ideal Population}}\\]\nnum_of_districts=2              # Number of districts\nallowed_pop_dev=0.05            # population deviation (fraction from ideal)\n# initialize constraints \nconstraints = initialize_constraints()\n# add population constraint \nadd_constraint!(constraints, PopulationConstraint(graph, num_of_districts, \n                                                    allowed_pop_dev))\n# initialize a random initial partition\nrng = PCG.PCGStateOneseq(UInt64, 4541901234)    # initialize a random number generator \npartition = LinkCutPartition(graph, constraints, num_of_districts; rng=rng, \n                                verbose=true);\nThere are other choices of constraints one can introduce which we will discuss later. The LinkCutPartition function tries to generate though a random algorithm a partition with num_of_districts districts that satisfies the specified constraints. It tires up to on the order of 100 times and returns the first acceptable partition generated. If all of the attempts fail, it throws an error message.\n\n\nDefining the Measure\nNext we define the target measure we want to sample from. In this simple example we will only consider log spanning forest energy that we will denote by \\(h(\\xi)\\) for a given partition \\(\\xi\\). It is defined by \\(h(\\xi)=\\log \\text{Tree}(\\xi)\\) where \\(\\text{Tree}(\\xi)\\) is the number spanning forest which induce the given partition \\(\\xi\\). When the parameter \\(\\gamma\\) bellow is taken to be zero then the measure is uniform on spanning forests while \\(\\gamma=1\\) corresponds to uniform on partitions. Normally, it is not wise to consider the uniform measure on partitions without an isoparmetric energy in the measure. However on a small graph like this, it does not matter.\nmeasure = Measure()     # build measure\ngamma=0.0               # typically a number in [0,1]\npush_energy!(measure, get_log_spanning_forests, gamma) # add spanning forests energy\n\n\nBuild the Proposal for Metropolis–Hastings MCMC\nWe now build the Markov Chain that will be used as a proposal in a Metropolis–Hastings Algorithm to construct a markov chains guaranteed to have the measure constructed above as a stationary measure.\ncycle_walk_2_tree = build_two_tree_cycle_walk(constraints)\ncycle_walk_1_tree = build_one_tree_cycle_walk(constraints)\ntwocycle_frac=0.1   # fraction of 2-tree cycle walks among total walks\nproposal = [(twocycle_frac, cycle_walk_2_tree), \n            (1.0-twocycle_frac, cycle_walk_1_tree)]\n\n\nChoose the Output\nWe now establish the name of the output file as well as fix a few parameters we want to be written to the file in addition to the vertex/node assignment that makes the current partition.\natlasName = \"cycleWalk\"*\"_grid4x4_\" * \"_gamma\" * string(gamma)*\"_kappa\"*string(twocycle_frac) *\".jsonl\"\noutput_file_path = joinpath(\"output\",\"grid\", atlasName) \nNext we construct a map writer that will output the current districting as well as some selected statistics about the districting and the run so far.\nad_param = Dict{String, Any}(\"popdev\" =&gt; allowed_pop_dev)   # specific info to write\nwriter = Writer(measure, constraints, partition, output_file_path; \n                additional_parameters=ad_param)\npush_writer!(writer, get_log_spanning_trees)        # add spanning trees count to writer\npush_writer!(writer, get_log_spanning_forests)      # add spanning forests count to writer\npush_writer!(writer, get_isoperimetric_scores)      # add isoperimetric scores to writer\n\n\nRun the Markov Chain\nWe now run the metropolized Cycle Walk with the proposal we constructed above.\ncycle_walk_2_tree_steps = 100\nsteps = Int(cycle_walk_2_tree_steps/twocycle_frac)\noutfreq = Int(1/twocycle_frac)\nprintln(\"running mcmc; outputting here: \"* output_file_path)\nrun_metropolis_hastings!(partition, proposal, measure, steps, rng,\n                         writer=writer, output_freq=outfreq)\nclose_writer(writer) # close atlas\n\n\nPutting Everything Together\nusing Pkg\nPkg.activate(\".\")       #   activate environment \nusing RandomNumbers     #   load Random Number package\nusing CycleWalk         #   load Cycle Walk package\n\n## build graph\npctGraphPath = joinpath(\".\",\"grid_graph_4_by_4.json\")\nnodeData = Set([\"node_name\", \"county\", \"population\", \"area\", \"border_length\"]);\ngraph = build_graph(pctGraphPath, \"population\", \"node_name\", nodeData;\n              area_col=\"area\", node_border_col=\"border_length\", \n              edge_perimeter_col=\"length\")\n\nnum_of_districts=2              # Number of districts\nallowed_pop_dev=0.05            # population deviation (fraction from ideal)\n# initialize constraints \nconstraints = initialize_constraints()\n# add population constraint \nadd_constraint!(constraints, PopulationConstraint(graph, num_of_districts, \n                                                    allowed_pop_dev))\n# initialize a random initial partition\nrng = PCG.PCGStateOneseq(UInt64, 4541901234)    # initialize a random number generator \npartition = LinkCutPartition(graph, constraints, num_of_districts; rng=rng, \n                                verbose=true);\n\nmeasure = Measure()     # build measure\ngamma=0.0               # typically a number in [0,1]\npush_energy!(measure, get_log_spanning_forests, gamma) # add spanning forests energy\n\ncycle_walk_2_tree = build_two_tree_cycle_walk(constraints)\ncycle_walk_1_tree = build_one_tree_cycle_walk(constraints)\ntwocycle_frac=0.1   # fraction of 2-tree cycle walks among total walks\nproposal = [(twocycle_frac, cycle_walk_2_tree), \n            (1.0-twocycle_frac, cycle_walk_1_tree)]\n\n#set output file name\natlasName = \"cycleWalk\"*\"_grid4x4_\" * \"_gamma\" * string(gamma)*\"_kappa\"*string(twocycle_frac) *\".jsonl\"\noutput_file_path = joinpath(\"output\",\"grid\", atlasName) \n\n# create writer and open output atlas\nad_param = Dict{String, Any}(\"popdev\" =&gt; allowed_pop_dev)   # specific info to write\nwriter = Writer(measure, constraints, partition, output_file_path; \n                additional_parameters=ad_param)\npush_writer!(writer, get_log_spanning_trees)        # add spanning trees count to writer\npush_writer!(writer, get_log_spanning_forests)      # add spanning forests count to writer\npush_writer!(writer, get_isoperimetric_scores)      # add isoperimetric scores to writer\n\n# Run the MCMC\ncycle_walk_2_tree_steps = 100\nsteps = Int(cycle_walk_2_tree_steps/twocycle_frac)\noutfreq = Int(1/twocycle_frac)\n\nprintln(\"running mcmc; outputting here: \"* output_file_path)\nrun_metropolis_hastings!(partition, proposal, measure, steps, rng,\n                         writer=writer, output_freq=outfreq)\nclose_writer(writer) # close atlas\n\n\n\nA second example: 10x10 hexagonal grid\nWe now consider a small variation on our previous example. We consider a planner region with a regular triangulation. The dual/adjacency graph is a hexagonal lattice. We begin by downloading the needed JSON adjacency file to our current directory.\ncurl  https://jonmjonm.github.io/QGDocs/Geo/Adjacency/hex_graph_10_by_10.json -o hex_graph_10_by_10.json\n\nA Modified Script\nWe now give code to run on the 10x10 hexagonal lattice. It will only require some small modifications from the previous example given above. Beyond the obvious such as modifying the input and output files, we will also increase the number of districts to 4 and decrease the allowed population deviation. This last step is possible as the number of element in each district increases providing finer granularity. We will also introduce an isodiametric score in the target measure to keep the districts compact no matter what constant is placed in front of the log spanning forests term in the energy. Recall that as that constant goes to one, the log spanning forests energy causes the probability measure to converge to the uniform measure on partitions if no other weights are used. The uniform measure on partitions is full of space-filling partitions that are very, very non-compact.\nusing Pkg\nPkg.activate(\".\")       #   activate environment \nusing RandomNumbers     #   load Random Number package\nusing CycleWalk         #   load Cycle Walk package\n\n## build graph\npctGraphPath = joinpath(\".\",\"hex_graph_10_by_10.json\")\nnodeData = Set([\"node_name\", \"county\", \"population\", \"area\", \"border_length\"]);\ngraph = build_graph(pctGraphPath, \"population\", \"node_name\", nodeData;\n              area_col=\"area\", node_border_col=\"border_length\", \n              edge_perimeter_col=\"length\")\n\nnum_of_districts=5              # Number of districts\nallowed_pop_dev=0.02            # population deviation (fraction from ideal)\n# initialize constraints \nconstraints = initialize_constraints()\n# add population constraint \nadd_constraint!(constraints, PopulationConstraint(graph, num_of_districts, \n                                                    allowed_pop_dev))\n# initialize a random initial partition\nrng = PCG.PCGStateOneseq(UInt64, 4541901234)    # initialize a random number generator \npartition = LinkCutPartition(graph, constraints, num_of_districts; rng=rng, \n                                verbose=true);\n\nmeasure = Measure()     # build measure\ngamma=0.0               # typically a number in [0,1]\niso_weight= 0.3         # weight on the sum of isoperimetric ratios; i.e. Polsby-Popper\npush_energy!(measure, get_log_spanning_forests, gamma) # add spanning forests energy\npush_energy!(measure, get_isoperimetric_score, iso_weight) # add isoperimetric score energy\n\ncycle_walk_2_tree = build_two_tree_cycle_walk(constraints)\ncycle_walk_1_tree = build_one_tree_cycle_walk(constraints)\ntwocycle_frac=0.1   # fraction of 2-tree cycle walks among total walks\nproposal = [(twocycle_frac, cycle_walk_2_tree), \n            (1.0-twocycle_frac, cycle_walk_1_tree)]\n\n#set output file name\natlasName = \"cycleWalk\"*\"_hex10x10_\" * \"_gamma\" * string(gamma)*\"_kappa\"\natlasName*= string(twocycle_frac)*\"_iso\"*string(iso_weight)*\".jsonl\"\n\noutput_file_path = joinpath(\"output\",\"grid\", atlasName) \n\n# create writer and open output atlas\nad_param = Dict{String, Any}(\"popdev\" =&gt; allowed_pop_dev)   # specific info to write\nwriter = Writer(measure, constraints, partition, output_file_path; \n                additional_parameters=ad_param)\npush_writer!(writer, get_log_spanning_trees)        # add spanning trees count to writer\npush_writer!(writer, get_log_spanning_forests)      # add spanning forests count to writer\npush_writer!(writer, get_isoperimetric_scores)      # add isoperimetric scores to writer\n\n# Run the MCMC\ncycle_walk_2_tree_steps = 100\nsteps = Int(cycle_walk_2_tree_steps/twocycle_frac)\noutfreq = Int(1/twocycle_frac)\n\nprintln(\"running mcmc; outputting here: \"* output_file_path)\nrun_metropolis_hastings!(partition, proposal, measure, steps, rng,\n                         writer=writer, output_freq=outfreq)\nclose_writer(writer) # close atlas\nThe lines change are 7, 13, 14, 27, 29, 38 and 39. Of these the most important of the non-cosmetic changes is the introduction of the isoparmetric score in line 29.\n\n\n\nA small realistic example: Connecticut Congressional Districts.",
    "crumbs": [
      "Home",
      "Cycle Walk"
    ]
  },
  {
    "objectID": "geographic.html",
    "href": "geographic.html",
    "title": "Geographic Files",
    "section": "",
    "text": "These are the basic formate used to hold the Adjacency file or dual graph for a region to be redistricted. It is based on the JSON output of the NetworkX Python library. An example for a 4x4 grid here grid_graph_4_by_4.json.\nSuch a file contains list of the nodes/vertices as a list under node. A sample node entry is\n    {\n        \"node_name\": \"(0,0)\",\n        \"id\": 0,\n        \"border_length\": 2,\n        \"x_location\": 0,\n        \"y_location\": 0,\n        \"area\": 1,\n        \"population\": 1,\n        \"county\": \"A\"\n    }\nwhere the id, area, population and border_length are required. They give the name by which the vertex/node are referred to as well as the area and population of the partition unit associated to the vertex/node. border_length entry give the length of the external boundary of the partition unit associated to the vertex/node. Hence of a vertex/node is interior this number is zero. The precise labels can be different than these as the name mapping to each piece of data can be specified at runtime.\nOne can also encode additional information. This example gives a node name in node_name, a location in the plane to help with plotting in x_location and y_location. It also records which county the node is in. This example uses fictitious county names of “A” and “B”. Additionally, the vote count for each party in a collection of elections is also often included.\nAfter the list of noted, there is an adjacency entry which contains one list for each of the vertices/nodes. The first list under adjacency gives the vertices/nodes that are adjacent to the first vertex/node listed above.\nFor example of the second entry in the adjacency list is the following list, then the 2nd note is adjacent to the 4th and 5th node listed with a boundary whose length is respectively one and two units.\n{\n    {\n    \"id\": 4,\n    \"length\": 1\n    },\n    {\n    \"id\": 5,\n    \"length\": 2\n    }\n}\n\n\n\nCollection of Sample Adjacency Files\n\n\n\n\n\n\n\nDescription\nFile Name\nComments\n\n\n\n\n4x4 Rectangular Grid\ngrid_graph_4_by_4.json\nSimple regular graph. All nodes have area and population 1. Grid divided into two counties labeled “A” and “B”\n\n\n8x8 Rectangular Grid\ngrid_graph_8_by_8.json\n8x8 version of previous.\n\n\n10x10 Rectangular Grid\ngrid_graph_10_by_10.json\n10x10 version of previous.\n\n\n10x10 Hexagonal Grid\nhex_graph_10_by_10.json\nThe graph is now hexagonal rather than square. Each node in the interior has 6 neighbors. This is the dual graph of a region partitioned into triangles.\n\n\nConnecticut Adjacency Graph\nCT_pct20.json\nPrecinct Adjacency Graph of the state of Connecticut. Contains county names in COUNTY, Precinct name in NAME, 2020 Population in POP20, area and border length in area and border_length, party votes from 2020 presidential general election in G20PREDEM and G20PREREP",
    "crumbs": [
      "Home",
      "Geographic Files"
    ]
  },
  {
    "objectID": "geographic.html#sec-json-adjacency-files",
    "href": "geographic.html#sec-json-adjacency-files",
    "title": "Geographic Files",
    "section": "",
    "text": "These are the basic formate used to hold the Adjacency file or dual graph for a region to be redistricted. It is based on the JSON output of the NetworkX Python library. An example for a 4x4 grid here grid_graph_4_by_4.json.\nSuch a file contains list of the nodes/vertices as a list under node. A sample node entry is\n    {\n        \"node_name\": \"(0,0)\",\n        \"id\": 0,\n        \"border_length\": 2,\n        \"x_location\": 0,\n        \"y_location\": 0,\n        \"area\": 1,\n        \"population\": 1,\n        \"county\": \"A\"\n    }\nwhere the id, area, population and border_length are required. They give the name by which the vertex/node are referred to as well as the area and population of the partition unit associated to the vertex/node. border_length entry give the length of the external boundary of the partition unit associated to the vertex/node. Hence of a vertex/node is interior this number is zero. The precise labels can be different than these as the name mapping to each piece of data can be specified at runtime.\nOne can also encode additional information. This example gives a node name in node_name, a location in the plane to help with plotting in x_location and y_location. It also records which county the node is in. This example uses fictitious county names of “A” and “B”. Additionally, the vote count for each party in a collection of elections is also often included.\nAfter the list of noted, there is an adjacency entry which contains one list for each of the vertices/nodes. The first list under adjacency gives the vertices/nodes that are adjacent to the first vertex/node listed above.\nFor example of the second entry in the adjacency list is the following list, then the 2nd note is adjacent to the 4th and 5th node listed with a boundary whose length is respectively one and two units.\n{\n    {\n    \"id\": 4,\n    \"length\": 1\n    },\n    {\n    \"id\": 5,\n    \"length\": 2\n    }\n}\n\n\n\nCollection of Sample Adjacency Files\n\n\n\n\n\n\n\nDescription\nFile Name\nComments\n\n\n\n\n4x4 Rectangular Grid\ngrid_graph_4_by_4.json\nSimple regular graph. All nodes have area and population 1. Grid divided into two counties labeled “A” and “B”\n\n\n8x8 Rectangular Grid\ngrid_graph_8_by_8.json\n8x8 version of previous.\n\n\n10x10 Rectangular Grid\ngrid_graph_10_by_10.json\n10x10 version of previous.\n\n\n10x10 Hexagonal Grid\nhex_graph_10_by_10.json\nThe graph is now hexagonal rather than square. Each node in the interior has 6 neighbors. This is the dual graph of a region partitioned into triangles.\n\n\nConnecticut Adjacency Graph\nCT_pct20.json\nPrecinct Adjacency Graph of the state of Connecticut. Contains county names in COUNTY, Precinct name in NAME, 2020 Population in POP20, area and border length in area and border_length, party votes from 2020 presidential general election in G20PREDEM and G20PREREP",
    "crumbs": [
      "Home",
      "Geographic Files"
    ]
  },
  {
    "objectID": "geographic.html#shapefiles",
    "href": "geographic.html#shapefiles",
    "title": "Geographic Files",
    "section": "Shapefiles",
    "text": "Shapefiles\nThe shapefile format is a geospatial vector data format for geographic information system (GIS) software. It was developed and regulated by Esri and is used to transfer data between many GIS systems. While the actual shape file has the extension .shp there are also to other required files with the extensions .shx and .dbf. All three are often zipped together into one file and called the “shapefile”. There are tools for creating a JSON adjacency file from a shapefile though a fair bit of cleaning is required.",
    "crumbs": [
      "Home",
      "Geographic Files"
    ]
  },
  {
    "objectID": "geographic.html#geojson",
    "href": "geographic.html#geojson",
    "title": "Geographic Files",
    "section": "GeoJSON",
    "text": "GeoJSON\nGeoJSON is a file formate that is the primary open sourse alternative to the shapefile formate.",
    "crumbs": [
      "Home",
      "Geographic Files"
    ]
  },
  {
    "objectID": "atlasIO.html",
    "href": "atlasIO.html",
    "title": "Atlas Files",
    "section": "",
    "text": "Atlas files contain a collection of map assignments or redistrictings. The format is a specialization of the JSONL format. Each line in an Atlas file is a JSON object. The first three lines describe the particular Atlas. Starting with the fourth line, each line is a JSON object that describes a map assignment. In addition to the map assignment, each line can also contain statistics and other information about the map assignment. These can be specified by the user.",
    "crumbs": [
      "Home",
      "Atlas Files"
    ]
  },
  {
    "objectID": "atlasIO.html#atlasio-code",
    "href": "atlasIO.html#atlasio-code",
    "title": "Atlas Files",
    "section": "AtlasIO code",
    "text": "AtlasIO code\nThe primary code is written in the Julia programming language, but it can be used in Python as well. The Julia AtlasIO library is an official Julia package and acn be loaded using the Julia Package Manager.\nThe Python libraries, as well as the Julia source code, can be found in the AtlasIO Git repository. This repository contains a number of tools to read in and manipulate Atlas files. The Python library can only read Atlas files, it cannot write them. The Julia library can read and write Atlas files.",
    "crumbs": [
      "Home",
      "Atlas Files"
    ]
  },
  {
    "objectID": "atlasIO.html#the-atlas-file-format",
    "href": "atlasIO.html#the-atlas-file-format",
    "title": "Atlas Files",
    "section": "The Atlas File Format",
    "text": "The Atlas File Format\nThe Atlas format is a JSONL (JSON Lines) format adapted hold district maps from redistricting efforts. The Atlas format is a simple extension of the JSONL format that allows for the storage of maps and their associated data in a single file. The AtlasIO.jl Julia library provides the ability to read and write Atlas files. The AtlasIO.py Python library, from the same git repository, provides the ability to read but not the ability to write files. This format was developed by the Duke Quantifying Gerrymandering Group. ### Structure of an Atlas File Each individual line of an Atlas file is JSON object. As such they can be read line by line unlike a single JSON. * This first line is a comment that identifies the file as an Atlas of maps and describes the Atlas format. * The second line is a JSON object that describes the basic information of the collection of maps saved in this Atlas. * The third line is a JSON object that describes the extra data assigned to each map. It can be adapted to the particular setting. In particular, it gives that data times and key names associated to the additional data. * Each of the following lines, starting with the 4th line, is a JSON object that describes a map and its associated data.\n\nFile Extension and Compression\nAtlas files use the file extension .jsonl if the file in Atlas is plain, uncompressed text. If the Atlas is compressed it will either use the file extension .jsonl.gz or .jsonl.bz2.\nThe .gz extension signifies the use of the standard Gnu Zip tools (gzip, gunzip, zcat) and can be read by a number of libraries and command line tools. These tools use the standard Deflate algorithm to compress data.\nThe .bz2 extension signifies the use of the standard BZip2 tools (bzip2, bzcat) and also can be read by a number of libraries and command line tools. These tools use the standard Burrows–Wheeler algorithm to compress data.\nThe Bzip2 compression format typically results in a smaller file than the Gzip compression format. However, the Bzip2 compression is slower to compress and uncompress. We also explored saving files by saving the incremental changes in the maps. However, it was decided that the advantage of using standard compression tools was significant in light of the very high compression ratios they delivered out of the box.\n\n\nWork Directly with Compressed Files\nOne nice feature of the AtlasIO libraries, both in Julia and Python, is that they can read and write compressed files directly. This both increase the speed of writing and decreases the size of the Atlas files significantly.\n\nCorrupted Compressed Files\nOne downside of directly writing compressed files is that the files can not be directly examined during the run and might be left in a corrupted state if the run is interrupted. A corrupted file can typically easily be largely recovered using\nzcat atlas-corrupted.jsonl.gz &gt;  atlas-fixed.jsonl\nYou can also use the zcat command to examine a file during a run.",
    "crumbs": [
      "Home",
      "Atlas Files"
    ]
  }
]